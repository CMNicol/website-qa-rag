{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0091589-d964-40c6-a4b7-09ecf597197e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ingest large amounts of data to a Vector DB (Amazon OpenSearch)\n",
    "**_Use of Amazon OpenSearch as a vector database for storing embeddings_**\n",
    "\n",
    "This notebook works well with the `conda_python3` kernel on a SageMaker Notebook `ml.t3.xlarge` instance.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Objective](#Objective)\n",
    "1. [Background](#Background-(Problem-Description-and-Approach))\n",
    "1. [Overall Workflow](#Overall-Workflow)\n",
    "1. [Create scripts for ingesting data into OpenSearch](#Create-scripts-for-ingesting-data-into-OpenSearch)\n",
    "1. [Download the data from the web and upload to S3](#Download-the-data-from-the-web-and-upload-to-S3)\n",
    "1. [Load the data in a OpenSearch index (Local mode)](#Load-the-data-in-a-OpenSearch-index-(Local-mode))\n",
    "1. [Load the data in a OpenSearch index via SageMaker Processing Job (Distributed mode)](#Load-the-data-in-a-OpenSearch-index-via-SageMaker-Processing-Job-(Distributed-mode))\n",
    "1. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c0dd9-bcb5-409f-8a4a-adab5ef47e42",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook illustrates how to use [`langchain`](https://python.langchain.com/en/latest/index.html) Amazon Sagemaker Endpoints and Amazon Sagemaker Processing Job to convert large amount of data into embeddings and ingest the text data along with its embeddings into an Amazon OpenSearch index.\n",
    "\n",
    "We use the documents from [sagemaker.readthedocs.io/en/stable](sagemaker.readthedocs.io/en/stable) as the dataset to convert into embeddings. The [`gpt-j-6b`](https://huggingface.co/EleutherAI/gpt-j-6b) large language model (LLM) is to generate the embeddings. \n",
    "\n",
    "To understand the code, you might also find it useful to refer to:\n",
    "\n",
    "- *[The langchain OpenSearch documentation](https://python.langchain.com/en/latest/ecosystem/opensearch.html)*\n",
    "- *[Amazon OpenSearch service documentation](https://docs.aws.amazon.com/opensearch-service/index.html)*\n",
    "- *[SageMaker Processing Job](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html)*\n",
    "---\n",
    "\n",
    "## Background (Problem Description and Approach)\n",
    "\n",
    "- **Problem statement**: \n",
    "\n",
    "Using LLMs for information retrieval tasks (such as question-answering) requires converting the knowledge corpus as well as user questions into vector embeddings. We want to generate these vector embeddings using an LLM hosted as a Amazon Sagemaker Endpoint and store it in a vector database of choice such as Amazon OpenSearch. For converting large amounts of data (TBs or PBs) we need a scalable system which can accomplish both converting the documents into embeddings, storing them in a vector database and provide low latency similarity search\n",
    "\n",
    "- **Our approach**: \n",
    "\n",
    "1. Host the LLM use to generate the embeddings as a SageMaker Endpoint with `instance_count` set to > 1 (the exact number depends upon time taken to generate the embeddings for the amount of data we have and the dollar amount we want to spend on it; more instances would mean greater cost but also lesser time taken).\n",
    "\n",
    "1. Place the data to be corpus of data in S3 (each document is a file stored as an object in S3).\n",
    "\n",
    "1. Use a Python script that uses [langchain](https://python.langchain.com/en/latest/index.html) and [Opensearch-py](https://pypi.org/project/opensearch-py/) to ingest the data into OpenSearch. Run the script locally on this notebook for testing.\n",
    "\n",
    "1. Create a Sagemaker Processing job with `instance_count` set to > 1 (usually matching the `instance_count` for the Sagemaker Endpoint). \n",
    "\n",
    "    Each instance of the SageMaker Processing Job runs a script that does the following:\n",
    "    - Processes a subset of files from S3.\n",
    "    - Uses langchain to read the files from the local filesystem and convert it into chunks.\n",
    "    - Creates a langchain `OpenSearchVectorSearch` object and provides it a `SagemakerJumpstartEmbeddings` object that enables it to talk to our Sagemaker Endpoint.\n",
    "    - Uses the langchain `OpenSearchVectorSearch` to create or get an existing Opensearch index and then ingests documents into the index which contain the original `text`, `embeddings` and `metadata`.\n",
    "    - Does this using Pytohn multiprocessing to achieve parallelization even within a single processing job instance and ensure maximum use of the Sagemaker Endpoint instance's GPU.\n",
    "    > **The advantage to using langchain as a wrapper for interfacing with a vector database is that it provides a generic pattern that can be used with any LLM and any vector store. Langchain automatically uses the OpenSearch bulk ingestion API endpoint for ingesting data rather than ingesting data one record at a time. Furthermore, langchain also provides an opinionated JSON structure that includes text and metadata alongwith the embeddings itself for storing embeddings in an OpenSearch index specifically for information retrieval use-cases**.\n",
    "\n",
    "- **Our tools**: [Amazon SageMaker SDK](https://sagemaker.readthedocs.io/en/stable/), [langchain](https://python.langchain.com/en/latest/index.html) and [Opensearch-py](https://pypi.org/project/opensearch-py/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a32334-88aa-431a-a306-f9fc3030f6cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overall Workflow\n",
    "\n",
    "The overall workflow for this notebook is as follows:\n",
    "\n",
    "1. Setup Sagemaker Endpoint for LLM to generate embeddings. This is done via the [`0_deploy_models.ipynb`](0_deploy_models.ipynb) notebook.\n",
    "1. Setup Amazon OpenSearch cluster by following steps described [here](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/gsg.html).\n",
    "1. Store the OpenSearch cluster credentials in AWS Secrets Manager by following steps described [here](https://docs.aws.amazon.com/secretsmanager/latest/userguide/managing-secrets.html).\n",
    "1. Download data from source and upload to S3.\n",
    "1. Run the Python script locally to ingest a subset of data into an OpenSearch index for testing.\n",
    "1. Run Sagemaker Processing Job which reads all data from S3 and runs the same Python script as above to ingest data into OpenSearch.\n",
    "    - As part of this step we also create a custom container to package langchain and opensearch Python packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81acd36d-a1c9-41b0-b412-7af957b2580f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup\n",
    "Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24ca243-fb69-4422-97ba-5a41c38a4b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: langchain==0.0.144 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.0.144)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (1.22.3)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (1.4.46)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (5.4.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (0.5.7)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (1.10.7)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (1.2.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (8.1.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (2.28.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (4.0.2)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.0.144) (2.8.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.144) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.144) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.144) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.144) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.144) (22.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.144) (1.3.1)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.144) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.144) (0.8.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.144) (3.19.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<2,>=1->langchain==0.0.144) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.144) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.144) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.144) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain==0.0.144) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.144) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.144) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.144) (3.0.9)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting opensearch-py==2.2.0\n",
      "  Downloading opensearch_py-2.2.0-py2.py3-none-any.whl (291 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py==2.2.0) (1.26.8)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py==2.2.0) (1.16.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py==2.2.0) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py==2.2.0) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py==2.2.0) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py==2.2.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py==2.2.0) (3.4)\n",
      "Installing collected packages: opensearch-py\n",
      "Successfully installed opensearch-py-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sagemaker --quiet\n",
    "!pip install ipywidgets==7.0.0 --quiet\n",
    "!pip install langchain==0.0.144\n",
    "!pip install opensearch-py==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822a0889-6149-4216-9633-ff66d201181c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.processing import ProcessingInput\n",
    "from langchain.document_loaders import ReadTheDocsLoader\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sagemaker.processing import ScriptProcessor, FrameworkProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d2fa335-c7a2-46ec-a14b-3e898f899975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "APP_NAME = \"llm-apps-demo\"\n",
    "WEBSITE=\"https://sagemaker.readthedocs.io/en/stable/\"\n",
    "DOMAIN=\"sagemaker.readthedocs.io\"\n",
    "DATA_DIR = \"docs\"\n",
    "OS_DOMAIN_EP = \"https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com\"\n",
    "MAX_OS_DOCS_PER_PUT = 500\n",
    "IMAGE = \"load-data-opensearch-custom\"\n",
    "IMAGE_TAG = \"latest\"\n",
    "S3_DATA_SOURCE = 's3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs/'\n",
    "OS_CREDS_SECRETID_IN_SECRET_MANAGER=\"opensearch_credentials\"\n",
    "CHUNK_SIZE_FOR_DOC_SPLIT = 500\n",
    "CHUNK_OVERLAP_FOR_DOC_SPLIT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7b4853-6d22-4d64-b4ae-b48d015f9b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format='%(asctime)s,%(module)s,%(processName)s,%(levelname)s,%(message)s', level=logging.INFO, stream=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15f5aa0-de08-42e2-b138-998ec1daefa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r embedding_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a9e808-bcfc-4715-9bd6-d94740b7501f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model_endpoint_name = \"qa-w-rag-huggingface-textembedding-gpt--2023-04-23-13-33-07-344\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54fbde3d-cc6c-49ef-bf82-ecaf69034c69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 17:31:11,937,1440690944,MainProcess,INFO,embedding_model_endpoint_name=qa-w-rag-huggingface-textembedding-gpt--2023-04-23-13-33-07-344\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"embedding_model_endpoint_name={embedding_model_endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25fc00c6-d5e3-4776-93a3-5d5ed6a3e729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 17:31:13,073,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 17:31:13,516,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 17:31:13,987,1638410780,MainProcess,INFO,aws_role=arn:aws:iam::015469603702:role/SageMakerRepoRole, aws_region=us-east-1, bucket=sagemaker-us-east-1-015469603702\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "model_version = \"*\"\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "logger.info(f\"aws_role={aws_role}, aws_region={aws_region}, bucket={bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2333d7-0c40-4586-9e4e-1f317859aaa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 17:31:26,109,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "# extend the SagemakerEndpointEmbeddings class from langchain to provide a custom embedding function\n",
    "class SagemakerEndpointEmbeddingsJumpStart(SagemakerEndpointEmbeddings):\n",
    "    def embed_documents(\n",
    "        self, texts: List[str], chunk_size: int = 5\n",
    "    ) -> List[List[float]]:\n",
    "        \"\"\"Compute doc embeddings using a SageMaker Inference Endpoint.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "            chunk_size: The chunk size defines how many input texts will\n",
    "                be grouped together as request. If None, will use the\n",
    "                chunk size specified by the class.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        _chunk_size = len(texts) if chunk_size > len(texts) else chunk_size\n",
    "        print(f\"len texts={len(texts)}\")\n",
    "        st = time.time()\n",
    "        for i in range(0, len(texts), _chunk_size):\n",
    "            response = self._embedding_func(texts[i:i + _chunk_size])\n",
    "            results.extend(response)\n",
    "        time_taken = time.time() - st\n",
    "        print(f\"got results for {len(texts)} in {time_taken}s\")\n",
    "        return results\n",
    "\n",
    "\n",
    "# class for serializing/deserializing requests/responses to/from the embeddings model\n",
    "class ContentHandler(ContentHandlerBase):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "\n",
    "        input_str = json.dumps({\"text_inputs\": prompt, **model_kwargs})\n",
    "        return input_str.encode('utf-8') \n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        embeddings = response_json[\"embedding\"]\n",
    "        if len(embeddings) == 1:\n",
    "            return [embeddings[0]]\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# all set to create the objects for the ContentHandler and \n",
    "# SagemakerEndpointEmbeddingsJumpStart classes\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "# note the name of the LLM Sagemaker endpoint, this is the model that we would\n",
    "# be using for generating the embeddings\n",
    "embeddings = SagemakerEndpointEmbeddingsJumpStart( \n",
    "    endpoint_name=embedding_model_endpoint_name,\n",
    "    region_name=aws_region, \n",
    "    content_handler=content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f4b53-23fe-4efd-9d5a-9211d7c2fe79",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Download the data from the web and upload to S3\n",
    "\n",
    "In this step we use `wget` to crawl a Python documentation style website data. All files other than `html`, `txt` and `md` are removed. This data download could take a long time so if you want to move forward immediately, skip to the next step which downloads some text data from a public S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee20648-7e87-4dc8-ac77-5698acde5962",
   "metadata": {},
   "source": [
    "**Set the `DOWNLOAD_DATA = \"yes\"` to download the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9f240968-f4fa-4fcb-b517-685f34de836f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "42dbecc5-9b1f-4a86-b905-c51dcdf926ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DOWNLOAD_DATA = \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f5d2acc1-198b-4f24-adb0-6ac8254d6cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/get_data.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/get_data.sh\n",
    "# This scripts uses wget to crawl the input website and \n",
    "# save the downloaded files in a given directory.\n",
    "echo \"input args=\"\n",
    "echo $@\n",
    "if [[ \"$1\" == \"yes\" ]];\n",
    "then\n",
    "    WEBSITE=$2\n",
    "    DOMAIN=$3\n",
    "    KB_DIR=$4    \n",
    "    # delete any existing folder for this data\n",
    "    rm -rf ${DOMAIN}\n",
    "    # download the data, this may take a few minutes or more depending upon the amount of content, network speed etc.\n",
    "    wget -e robots=off --recursive --no-clobber --page-requisites --html-extension --convert-links --restrict-file-names=windows --domains ${DOMAIN} --no-parent ${WEBSITE}\n",
    "    # remove all files other than html (we are only interested in embeddings for text for this example)\n",
    "    rm -f `find ${DOMAIN} -type f ! -name \"*.html\"`\n",
    "else\n",
    "    echo DOWNLOAD_DATA=$1, not downloading new data\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4729828a-3f07-412b-9ca5-836bf05c0214",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWNLOAD_DATA=no, not downloading new data\n"
     ]
    }
   ],
   "source": [
    "!chmod +x scripts/get_data.sh\n",
    "!./scripts/get_data.sh $DOWNLOAD_DATA $WEBSITE $DOMAIN $DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "895293b2-edec-4a70-98be-81feab16a4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/tabular/catboost.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/tabular/catboost.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/tabular/tabtransformer.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/tabular/tabtransformer.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/tabular/factorization_machines.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/tabular/factorization_machines.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/tabular/autogluon.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/tabular/autogluon.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/sagemaker.amazon.amazon_estimator.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/sagemaker.amazon.amazon_estimator.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/tabular/xgboost.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/tabular/xgboost.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/tabular/lightgbm.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/tabular/lightgbm.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/tabular/linear_learner.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/tabular/linear_learner.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/tabular/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/tabular/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/tabular/knn.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/tabular/knn.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/blazing_text.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/blazing_text.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/machine_translation_hugging_face.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/machine_translation_hugging_face.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/named_entity_recognition_hugging_face.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/named_entity_recognition_hugging_face.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/lda.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/lda.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/sequence_to_sequence.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/sequence_to_sequence.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/ntm.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/ntm.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/object2vec.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/object2vec.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/sentence_pair_classification_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/sentence_pair_classification_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/text_classification_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/text_classification_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/time_series/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/time_series/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/text_summarization_hugging_face.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/text_summarization_hugging_face.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/sentence_pair_classification_hugging_face.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/sentence_pair_classification_hugging_face.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/ipinsights.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/ipinsights.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/question_answering_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/question_answering_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/kmeans.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/kmeans.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/image_classification_mxnet.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/image_classification_mxnet.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/pca.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/pca.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/text/text_generation_hugging_face.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/text/text_generation_hugging_face.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/time_series/deep_ar.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/time_series/deep_ar.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/randomcutforest.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/unsupervised/randomcutforest.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/image_embedding_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/image_embedding_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/image_classification_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/image_classification_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/semantic_segmentation_mxnet.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/semantic_segmentation_mxnet.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/image_classification_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/image_classification_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/object_detection_mxnet_gluoncv.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/object_detection_mxnet_gluoncv.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/object_detection_mxnet.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/object_detection_mxnet.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/object_detection_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/object_detection_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/object_detection_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/object_detection_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/text_embedding_tensorflow_mxnet.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/text_embedding_tensorflow_mxnet.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/amazon_sagemaker_featurestore.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/amazon_sagemaker_featurestore.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/governance/model_card.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/governance/model_card.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/analytics.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/analytics.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/semantic_segmentation_mxnet_gluoncv.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/semantic_segmentation_mxnet_gluoncv.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/amazon_sagemaker_processing.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/amazon_sagemaker_processing.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/async_inference.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/async_inference.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/governance/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/governance/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/explainer.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/explainer.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/model.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/pipeline.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/pipeline.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/predictors.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/model_collection.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/model_collection.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/multi_data_model.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/multi_data_model.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/predictor_async.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/predictor_async.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/serializers.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/serializers.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/serverless.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/serverless.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/debugger.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/debugger.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/inference/transformer.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/inference/transformer.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/automl.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/automl.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/analytics.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/analytics.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/algorithm.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/algorithm.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/prep_data/feature_store.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/prep_data/feature_store.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/distributed.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/distributed.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/parameter.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/parameter.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/archives.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/archives.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/latest/smd_data_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/latest/smd_data_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.0.0/smd_data_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.1.x/smd_data_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.1.x/smd_data_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/processing.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/processing.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.2.x/smd_data_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/latest.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/latest.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/estimators.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/estimators.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/latest/smd_data_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.1.x/smd_data_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel_use_sm_pysdk.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel_use_sm_pysdk.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.2.x/smd_data_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1_0_0.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1_0_0.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1_1_x.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1_1_x.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel_general.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel_general.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel_release_notes/smd_data_parallel_change_log.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/algorithms/vision/instance_segmentation_mxnet.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/algorithms/vision/instance_segmentation_mxnet.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1_2_x.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1_2_x.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/archives.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/archives.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_common_api.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_common_api.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel_release_notes/smd_model_parallel_change_log.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel_release_notes/smd_model_parallel_change_log.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.1.0/smd_model_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.1.0/smd_model_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.10.0/smd_model_parallel_pytorch_tensor_parallel.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.10.0/smd_model_parallel_pytorch_tensor_parallel.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.10.0/smd_model_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.10.0/smd_model_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.1.0/smd_model_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.1.0/smd_model_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.1.0/smd_model_parallel_common_api.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.1.0/smd_model_parallel_common_api.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.10.0/smd_model_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.10.0/smd_model_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.10.0/smd_model_parallel_common_api.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.10.0/smd_model_parallel_common_api.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_pytorch_tensor_parallel.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/latest/smd_model_parallel_pytorch_tensor_parallel.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.2.0/smd_model_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.2.0/smd_model_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.3.0/smd_model_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.3.0/smd_model_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.2.0/smd_model_parallel_common_api.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.2.0/smd_model_parallel_common_api.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.3.0/smd_model_parallel_common_api.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.3.0/smd_model_parallel_common_api.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.3.0/smd_model_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.3.0/smd_model_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.4.0/smd_model_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.4.0/smd_model_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.4.0/smd_model_parallel_common_api.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.4.0/smd_model_parallel_common_api.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.4.0/smd_model_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.4.0/smd_model_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.6.0/smd_model_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.6.0/smd_model_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.6.0/smd_model_parallel_pytorch_tensor_parallel.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.6.0/smd_model_parallel_pytorch_tensor_parallel.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.5.0/smd_model_parallel_common_api.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.5.0/smd_model_parallel_common_api.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.2.0/smd_model_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.2.0/smd_model_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.9.0/smd_model_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.9.0/smd_model_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.6.0/smd_model_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.6.0/smd_model_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.9.0/smd_model_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.9.0/smd_model_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.9.0/smd_model_parallel_pytorch_tensor_parallel.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.9.0/smd_model_parallel_pytorch_tensor_parallel.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.5.0/smd_model_parallel_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.5.0/smd_model_parallel_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.9.0/smd_model_parallel_common_api.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.9.0/smd_model_parallel_common_api.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.5.0/smd_model_parallel_tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.5.0/smd_model_parallel_tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_1_0.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_1_0.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_2_0.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_2_0.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_9_0.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_9_0.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/tuner.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/config.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/config.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_6_0.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_6_0.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_10_0.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_10_0.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_3_0.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_3_0.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/environment_variables.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/environment_variables.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/inputs.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_4_0.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_4_0.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/hyperparameters.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/hyperparameters.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_5_0.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1_5_0.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/instance_group.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/instance_group.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/lambda_helper.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/lambda_helper.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/script_uris.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/script_uris.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/network.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/network.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/debugger.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/debugger.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/s3.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/s3.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/session.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/experiments/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/experiments/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.6.0/smd_model_parallel_common_api.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/training/smp_versions/v1.6.0/smd_model_parallel_common_api.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/chainer/using_chainer.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/chainer/using_chainer.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/api/utility/model_uris.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/api/utility/model_uris.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/chainer/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/chainer/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/chainer/sagemaker.chainer.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/chainer/sagemaker.chainer.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/estimators.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/estimators.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/djl/using_djl.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/djl/using_djl.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/djl/sagemaker.djl_inference.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/djl/sagemaker.djl_inference.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/djl/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/djl/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/experiments/sagemaker.experiments.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/experiments/sagemaker.experiments.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/mxnet/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/mxnet/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/rl/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/rl/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/pytorch/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/pytorch/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/mxnet/using_mxnet.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/mxnet/using_mxnet.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/mxnet/sagemaker.mxnet.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/sparkml/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/sparkml/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/rl/sagemaker.rl.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/rl/sagemaker.rl.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/sparkml/sagemaker.sparkml.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/sparkml/sagemaker.sparkml.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/deploying_tensorflow_serving.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/deploying_tensorflow_serving.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/sklearn/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/sklearn/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/rl/using_rl.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/rl/using_rl.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/xgboost/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/xgboost/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/upgrade_from_legacy.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/upgrade_from_legacy.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/xgboost/using_xgboost.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/xgboost/using_xgboost.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/genindex.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/genindex.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/processing.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/processing.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/frameworks/xgboost/xgboost.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/frameworks/xgboost/xgboost.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/search.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/search.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/using_mxnet.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/using_mxnet.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/tuner.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/tuner.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/predictors.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/predictors.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/transformer.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/transformer.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/sagemaker.mxnet.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/sagemaker.mxnet.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/workflows/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/workflows/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/workflows/airflow/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/workflows/airflow/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/model_monitor.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/model_monitor.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/workflows/airflow/using_workflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/workflows/airflow/using_workflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/v2.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/v2.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/s3.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/s3.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/workflows/airflow/sagemaker.workflow.airflow.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/workflows/airflow/sagemaker.workflow.airflow.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/workflows/lineage/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/workflows/lineage/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/workflows/pipelines/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/workflows/pipelines/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/overview.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/overview.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/workflows/step_functions/index.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/workflows/step_functions/index.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/workflows/lineage/sagemaker.lineage.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/workflows/lineage/sagemaker.lineage.html\n",
      "upload: sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html to s3://sagemaker-us-east-1-015469603702/llm-apps-demo/sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html\n"
     ]
    }
   ],
   "source": [
    "# optional step, uncomment if you would like to use this data for a future run\n",
    "# by downloading it from S3\n",
    "!aws s3 cp --recursive $DOMAIN/ s3://$bucket/$APP_NAME/$DOMAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95833d54-d6bb-4d4c-97b6-9157cd9bcabf",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Create scripts for ingesting data into `OpenSearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdb00176-452a-4fe2-999e-322da380a6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘src’: File exists\n",
      "mkdir: cannot create directory ‘scripts’: File exists\n",
      "mkdir: cannot create directory ‘container’: File exists\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create directories for storing scripts and Dockerfile\n",
    "\"\"\"\n",
    "!mkdir src\n",
    "!mkdir scripts\n",
    "!mkdir container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a0545c-b593-4319-b355-4dacee393416",
   "metadata": {},
   "source": [
    "### Read credentials from AWS Secrets Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99538cbf-aa7b-4dd4-b01e-8d4932a088d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container/credentials.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/credentials.py\n",
    "\n",
    "\"\"\"\n",
    "Retrieve Snowflake password for given username from AWS SecretsManager\n",
    "\"\"\"\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "def get_credentials(secret_id: str, region_name: str) -> str:\n",
    "    \n",
    "    client = boto3.client('secretsmanager', region_name=region_name)\n",
    "    response = client.get_secret_value(SecretId=secret_id)\n",
    "    secrets_value = json.loads(response['SecretString'])    \n",
    "    \n",
    "    return secrets_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de107289-6b61-445e-ad53-310db4f08946",
   "metadata": {},
   "source": [
    "### SageMaker embeddings for langchain\n",
    "\n",
    "langchain provides the [`SagemakerEndpointEmbeddings`]() class which is a wrapper around a functionality to talk to a Sagemaker Endpoint to generate embeddings. We will override the `embed_documents` function to define our own batching strategy for sending requests to the model (multiple requests are sent in one model invocation). Similarly, we extend the `ContentHandlerBase` class to provide implementation for two abstract methods which define how to process (encode/decode) the input data sent to the model and the output received from the model.\n",
    "\n",
    "We finally create a `SagemakerEndpointEmbeddingsJumpStart` object that puts all this together and can now be used by langchain to talk to an LLM deployed as a Sagemaker Endpoint to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3385847f-094f-4eaa-9e3c-9fde1b262bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container/sm_helper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/sm_helper.py\n",
    "\n",
    "\"\"\"\n",
    "Helper functions for using Samgemaker Endpoint via langchain\n",
    "\"\"\"\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from typing import List\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# extend the SagemakerEndpointEmbeddings class from langchain to provide a custom embedding function\n",
    "class SagemakerEndpointEmbeddingsJumpStart(SagemakerEndpointEmbeddings):\n",
    "    def embed_documents(\n",
    "        self, texts: List[str], chunk_size: int = 5\n",
    "    ) -> List[List[float]]:\n",
    "        \"\"\"Compute doc embeddings using a SageMaker Inference Endpoint.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "            chunk_size: The chunk size defines how many input texts will\n",
    "                be grouped together as request. If None, will use the\n",
    "                chunk size specified by the class.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        _chunk_size = len(texts) if chunk_size > len(texts) else chunk_size\n",
    "        st = time.time()\n",
    "        for i in range(0, len(texts), _chunk_size):\n",
    "            response = self._embedding_func(texts[i:i + _chunk_size])\n",
    "            results.extend(response)\n",
    "        time_taken = time.time() - st\n",
    "        logger.info(f\"got results for {len(texts)} in {time_taken}s, length of embeddings list is {len(results)}\")\n",
    "        return results\n",
    "\n",
    "\n",
    "# class for serializing/deserializing requests/responses to/from the embeddings model\n",
    "class ContentHandler(ContentHandlerBase):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "\n",
    "        input_str = json.dumps({\"text_inputs\": prompt, **model_kwargs})\n",
    "        return input_str.encode('utf-8') \n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        embeddings = response_json[\"embedding\"]\n",
    "        if len(embeddings) == 1:\n",
    "            return [embeddings[0]]\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e31e78c-f65c-4662-8bb6-f98ed880d307",
   "metadata": {},
   "source": [
    "### Load data into OpenSearch script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d1e2e17-538b-45e6-bbe3-a29fe8a9e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing container/load_data_into_opensearch.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/load_data_into_opensearch.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# this is needed because the credentials.py and sm_helper.py\n",
    "# are in /code directory of the custom container we are going \n",
    "# to create for Sagemaker Processing Job\n",
    "sys.path.insert(1, '/code')\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import multiprocessing as mp\n",
    "from itertools import repeat\n",
    "from functools import partial\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "from credentials import get_credentials\n",
    "from langchain.document_loaders import ReadTheDocsLoader\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sm_helper import SagemakerEndpointEmbeddingsJumpStart, ContentHandler\n",
    "\n",
    "# global constants\n",
    "MAX_OS_DOCS_PER_PUT = 500\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format='%(asctime)s,%(module)s,%(processName)s,%(levelname)s,%(message)s', level=logging.INFO, stream=sys.stderr)\n",
    "\n",
    "def process_shard(shard, embeddings_model_endpoint_name, aws_region, os_index_name, os_domain_ep, os_http_auth): \n",
    "    logger.info(f'Starting process_shard of {len(shard)} chunks.')\n",
    "    st = time.time()\n",
    "    # all set to create the objects for the ContentHandler and \n",
    "    # SagemakerEndpointEmbeddingsJumpStart classes\n",
    "    content_handler = ContentHandler()\n",
    "\n",
    "    # note the name of the LLM Sagemaker endpoint, this is the model that we would\n",
    "    # be using for generating the embeddings\n",
    "    embeddings = SagemakerEndpointEmbeddingsJumpStart( \n",
    "        endpoint_name=embeddings_model_endpoint_name,\n",
    "        region_name=aws_region, \n",
    "        content_handler=content_handler\n",
    "    )\n",
    "    docsearch = OpenSearchVectorSearch(index_name=os_index_name,\n",
    "                                       embedding_function=embeddings,\n",
    "                                       opensearch_url=os_domain_ep,\n",
    "                                       http_auth=os_http_auth)\n",
    "    texts = [doc.page_content for doc in shard]\n",
    "    logger.info(f\"process_shard, there are {len(texts)} texts to be added\")\n",
    "    docsearch.add_documents(documents=shard)\n",
    "    et = time.time() - st\n",
    "    logger.info(f'Shard completed in {et} seconds.')\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--opensearch-cluster-domain\", type=str, default=None)\n",
    "    parser.add_argument(\"--opensearch-secretid\", type=str, default=None)\n",
    "    parser.add_argument(\"--opensearch-index-name\", type=str, default=None)\n",
    "    parser.add_argument(\"--aws-region\", type=str, default=\"us-east-1\")\n",
    "    parser.add_argument(\"--embeddings-model-endpoint-name\", type=str, default=None)\n",
    "    parser.add_argument(\"--chunk-size-for-doc-split\", type=int, default=500)\n",
    "    parser.add_argument(\"--chunk-overlap-for-doc-split\", type=int, default=30)\n",
    "    parser.add_argument(\"--input-data-dir\", type=str, default=\"/opt/ml/processing/input_data\")\n",
    "    parser.add_argument(\"--process-count\", type=int, default=2)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    logger.info(\"Received arguments {}\".format(args))\n",
    "    \n",
    "    # list all the files\n",
    "    files = glob.glob(os.path.join(args.input_data_dir, \"*.*\"))\n",
    "    logger.info(f\"there are {len(files)} files to process in the {args.input_data_dir} folder\")\n",
    "    \n",
    "    # retrieve secret to talk to opensearch\n",
    "    creds = get_credentials(args.opensearch_secretid, args.aws_region)\n",
    "    http_auth = (creds['username'], creds['password'])\n",
    "    \n",
    "    \n",
    "    loader = ReadTheDocsLoader(args.input_data_dir)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        # Set a really small chunk size, just to show.\n",
    "        chunk_size=args.chunk_size_for_doc_split,\n",
    "        chunk_overlap=args.chunk_overlap_for_doc_split,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    # Stage one: read all the docs, split them into chunks. \n",
    "    st = time.time() \n",
    "    logger.info('Loading documents ...')\n",
    "    docs = loader.load()\n",
    "    \n",
    "    \n",
    "    chunks = text_splitter.create_documents([doc.page_content for doc in docs], metadatas=[doc.metadata for doc in docs])\n",
    "    et = time.time() - st\n",
    "    logger.info(f'Time taken: {et} seconds. {len(chunks)} chunks generated') \n",
    "    \n",
    "    \n",
    "    db_shards = (len(chunks) // MAX_OS_DOCS_PER_PUT) + 1\n",
    "    print(f'Loading chunks into vector store ... using {db_shards} shards') \n",
    "    st = time.time()\n",
    "    shards = np.array_split(chunks, db_shards)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    with mp.Pool(processes = args.process_count) as pool:\n",
    "        results = pool.map(partial(process_shard,\n",
    "                           embeddings_model_endpoint_name=args.embeddings_model_endpoint_name,\n",
    "                           aws_region=args.aws_region,\n",
    "                           os_index_name=args.opensearch_index_name,\n",
    "                           os_domain_ep=args.opensearch_cluster_domain,\n",
    "                           os_http_auth=http_auth                         \n",
    "                                  ),\n",
    "                           shards)\n",
    "    \n",
    "    t2 = time.time()\n",
    "\n",
    "    # all set to create the objects for the ContentHandler and \n",
    "    # SagemakerEndpointEmbeddingsJumpStart classes\n",
    "    content_handler = ContentHandler()\n",
    "\n",
    "    # note the name of the LLM Sagemaker endpoint, this is the model that we would\n",
    "    # be using for generating the embeddings\n",
    "    embeddings = SagemakerEndpointEmbeddingsJumpStart( \n",
    "        endpoint_name=args.embeddings_model_endpoint_name,\n",
    "        region_name=args.aws_region, \n",
    "        content_handler=content_handler\n",
    "    )\n",
    "    docsearch = OpenSearchVectorSearch(index_name=args.opensearch_index_name,\n",
    "                                       embedding_function=embeddings,\n",
    "                                       opensearch_url=args.opensearch_cluster_domain,\n",
    "                                       http_auth=http_auth)\n",
    "    count = docsearch.client.count()\n",
    "    logger.info(f'run time in seconds: {t2-t1:.2f}, index count={count}')\n",
    "    logger.info(\"all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc578257-1bd7-44e6-b338-9dac375771c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Load the data in a `OpenSearch` index (Local mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bfeae41-bab1-4f35-9368-abda7af74b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-23 22:56:36,087,load_data_into_opensearch,MainProcess,INFO,Received arguments Namespace(opensearch_cluster_domain='https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com', opensearch_secretid='opensearch_credentials', opensearch_index_name='sagemakerdocs2', aws_region='us-east-1', embeddings_model_endpoint_name='qa-w-rag-huggingface-textembedding-gpt--2023-04-23-13-33-07-344', chunk_size_for_doc_split=500, chunk_overlap_for_doc_split=30, input_data_dir='sagemaker.readthedocs')\n",
      "there are 211 files to process in the sagemaker.readthedocs folder\n",
      "2023-04-23 22:56:36,114,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/document_loaders/readthedocs.py:30: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 30 of the file /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/document_loaders/readthedocs.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  _ = BeautifulSoup(\n",
      "2023-04-23 22:56:36,432,load_data_into_opensearch,MainProcess,INFO,Loading documents ...\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/document_loaders/readthedocs.py:46: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 46 of the file /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/document_loaders/readthedocs.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(data, **self.bs_kwargs)\n",
      "2023-04-23 22:56:48,294,load_data_into_opensearch,MainProcess,INFO,Time taken: 11.86230731010437 seconds. 6840 chunks generated\n",
      "Loading chunks into vector store ... using 14 shards\n",
      "2023-04-23 22:56:48,332,load_data_into_opensearch,ForkPoolWorker-1,INFO,Starting process_shard of 489 chunks.\n",
      "2023-04-23 22:56:48,339,load_data_into_opensearch,ForkPoolWorker-2,INFO,Starting process_shard of 489 chunks.\n",
      "2023-04-23 22:56:48,357,credentials,ForkPoolWorker-1,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 22:56:48,370,credentials,ForkPoolWorker-2,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 22:56:48,635,load_data_into_opensearch,ForkPoolWorker-2,INFO,process_shard, there are 489 texts to be added\n",
      "2023-04-23 22:56:48,681,load_data_into_opensearch,ForkPoolWorker-1,INFO,process_shard, there are 489 texts to be added\n",
      "2023-04-23 22:57:53,101,sm_helper,ForkPoolWorker-2,INFO,got results for 489 in 64.46649885177612s, length of embeddings list is 489\n",
      "2023-04-23 22:57:53,309,sm_helper,ForkPoolWorker-1,INFO,got results for 489 in 64.62769198417664s, length of embeddings list is 489\n",
      "2023-04-23 22:57:58,236,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:3.404s]\n",
      "2023-04-23 22:57:59,113,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.866s]\n",
      "2023-04-23 22:57:59,134,load_data_into_opensearch,ForkPoolWorker-2,INFO,Shard completed in 70.79405856132507 seconds.\n",
      "2023-04-23 22:57:59,135,load_data_into_opensearch,ForkPoolWorker-2,INFO,Starting process_shard of 489 chunks.\n",
      "2023-04-23 22:57:59,154,credentials,ForkPoolWorker-2,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 22:57:59,187,load_data_into_opensearch,ForkPoolWorker-2,INFO,process_shard, there are 489 texts to be added\n",
      "2023-04-23 22:57:59,297,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:4.274s]\n",
      "2023-04-23 22:57:59,335,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.026s]\n",
      "2023-04-23 22:57:59,361,load_data_into_opensearch,ForkPoolWorker-1,INFO,Shard completed in 71.02819871902466 seconds.\n",
      "2023-04-23 22:57:59,362,load_data_into_opensearch,ForkPoolWorker-1,INFO,Starting process_shard of 489 chunks.\n",
      "2023-04-23 22:57:59,382,credentials,ForkPoolWorker-1,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 22:57:59,419,load_data_into_opensearch,ForkPoolWorker-1,INFO,process_shard, there are 489 texts to be added\n",
      "2023-04-23 22:59:04,310,sm_helper,ForkPoolWorker-2,INFO,got results for 489 in 65.12274503707886s, length of embeddings list is 489\n",
      "2023-04-23 22:59:07,858,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:1.969s]\n",
      "2023-04-23 22:59:07,990,sm_helper,ForkPoolWorker-1,INFO,got results for 489 in 68.57021498680115s, length of embeddings list is 489\n",
      "2023-04-23 22:59:09,042,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:1.172s]\n",
      "2023-04-23 22:59:09,072,load_data_into_opensearch,ForkPoolWorker-2,INFO,Shard completed in 69.9359073638916 seconds.\n",
      "2023-04-23 22:59:09,078,load_data_into_opensearch,ForkPoolWorker-2,INFO,Starting process_shard of 489 chunks.\n",
      "2023-04-23 22:59:09,100,credentials,ForkPoolWorker-2,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 22:59:09,134,load_data_into_opensearch,ForkPoolWorker-2,INFO,process_shard, there are 489 texts to be added\n",
      "2023-04-23 22:59:11,400,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:1.803s]\n",
      "2023-04-23 22:59:12,034,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.624s]\n",
      "2023-04-23 22:59:12,057,load_data_into_opensearch,ForkPoolWorker-1,INFO,Shard completed in 72.69451117515564 seconds.\n",
      "2023-04-23 22:59:12,064,load_data_into_opensearch,ForkPoolWorker-1,INFO,Starting process_shard of 489 chunks.\n",
      "2023-04-23 22:59:12,083,credentials,ForkPoolWorker-1,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 22:59:12,113,load_data_into_opensearch,ForkPoolWorker-1,INFO,process_shard, there are 489 texts to be added\n",
      "2023-04-23 23:00:14,892,sm_helper,ForkPoolWorker-2,INFO,got results for 489 in 65.7582335472107s, length of embeddings list is 489\n",
      "2023-04-23 23:00:18,548,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:1.928s]\n",
      "2023-04-23 23:00:19,215,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.651s]\n",
      "2023-04-23 23:00:19,235,load_data_into_opensearch,ForkPoolWorker-2,INFO,Shard completed in 70.1574158668518 seconds.\n",
      "2023-04-23 23:00:19,237,load_data_into_opensearch,ForkPoolWorker-2,INFO,Starting process_shard of 489 chunks.\n",
      "2023-04-23 23:00:19,257,credentials,ForkPoolWorker-2,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 23:00:19,286,load_data_into_opensearch,ForkPoolWorker-2,INFO,process_shard, there are 489 texts to be added\n",
      "2023-04-23 23:00:20,845,sm_helper,ForkPoolWorker-1,INFO,got results for 489 in 68.73128700256348s, length of embeddings list is 489\n",
      "2023-04-23 23:00:24,235,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:1.875s]\n",
      "2023-04-23 23:00:24,869,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.623s]\n",
      "2023-04-23 23:00:24,897,load_data_into_opensearch,ForkPoolWorker-1,INFO,Shard completed in 72.83265852928162 seconds.\n",
      "2023-04-23 23:00:24,898,load_data_into_opensearch,ForkPoolWorker-1,INFO,Starting process_shard of 489 chunks.\n",
      "2023-04-23 23:00:24,925,credentials,ForkPoolWorker-1,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 23:00:24,962,load_data_into_opensearch,ForkPoolWorker-1,INFO,process_shard, there are 489 texts to be added\n",
      "2023-04-23 23:01:27,668,sm_helper,ForkPoolWorker-2,INFO,got results for 489 in 68.38230085372925s, length of embeddings list is 489\n",
      "2023-04-23 23:01:31,391,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:2.020s]\n",
      "2023-04-23 23:01:32,022,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.621s]\n",
      "2023-04-23 23:01:32,042,load_data_into_opensearch,ForkPoolWorker-2,INFO,Shard completed in 72.80496573448181 seconds.\n",
      "2023-04-23 23:01:32,233,load_data_into_opensearch,ForkPoolWorker-2,INFO,Starting process_shard of 488 chunks.\n",
      "2023-04-23 23:01:32,263,credentials,ForkPoolWorker-2,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 23:01:32,294,load_data_into_opensearch,ForkPoolWorker-2,INFO,process_shard, there are 488 texts to be added\n",
      "2023-04-23 23:01:32,813,sm_helper,ForkPoolWorker-1,INFO,got results for 489 in 67.85079073905945s, length of embeddings list is 489\n",
      "2023-04-23 23:01:36,587,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:1.822s]\n",
      "2023-04-23 23:01:37,229,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.629s]\n",
      "2023-04-23 23:01:37,250,load_data_into_opensearch,ForkPoolWorker-1,INFO,Shard completed in 72.35103964805603 seconds.\n",
      "2023-04-23 23:01:37,431,load_data_into_opensearch,ForkPoolWorker-1,INFO,Starting process_shard of 488 chunks.\n",
      "2023-04-23 23:01:37,452,credentials,ForkPoolWorker-1,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 23:01:37,487,load_data_into_opensearch,ForkPoolWorker-1,INFO,process_shard, there are 488 texts to be added\n",
      "2023-04-23 23:02:36,298,sm_helper,ForkPoolWorker-2,INFO,got results for 488 in 64.00391030311584s, length of embeddings list is 488\n",
      "2023-04-23 23:02:39,847,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:1.859s]\n",
      "2023-04-23 23:02:40,459,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.602s]\n",
      "2023-04-23 23:02:40,490,load_data_into_opensearch,ForkPoolWorker-2,INFO,Shard completed in 68.25674748420715 seconds.\n",
      "2023-04-23 23:02:40,492,load_data_into_opensearch,ForkPoolWorker-2,INFO,Starting process_shard of 488 chunks.\n",
      "2023-04-23 23:02:40,513,credentials,ForkPoolWorker-2,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 23:02:40,543,load_data_into_opensearch,ForkPoolWorker-2,INFO,process_shard, there are 488 texts to be added\n",
      "2023-04-23 23:02:42,649,sm_helper,ForkPoolWorker-1,INFO,got results for 488 in 65.16101098060608s, length of embeddings list is 488\n",
      "2023-04-23 23:02:46,141,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:1.849s]\n",
      "2023-04-23 23:02:46,741,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.591s]\n",
      "2023-04-23 23:02:46,770,load_data_into_opensearch,ForkPoolWorker-1,INFO,Shard completed in 69.33876824378967 seconds.\n",
      "2023-04-23 23:02:46,773,load_data_into_opensearch,ForkPoolWorker-1,INFO,Starting process_shard of 488 chunks.\n",
      "2023-04-23 23:02:46,799,credentials,ForkPoolWorker-1,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 23:02:46,847,load_data_into_opensearch,ForkPoolWorker-1,INFO,process_shard, there are 488 texts to be added\n",
      "2023-04-23 23:03:45,788,sm_helper,ForkPoolWorker-2,INFO,got results for 488 in 65.24415349960327s, length of embeddings list is 488\n",
      "2023-04-23 23:03:49,205,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:1.823s]\n",
      "2023-04-23 23:03:49,881,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.660s]\n",
      "2023-04-23 23:03:49,904,load_data_into_opensearch,ForkPoolWorker-2,INFO,Shard completed in 69.411212682724 seconds.\n",
      "2023-04-23 23:03:49,912,load_data_into_opensearch,ForkPoolWorker-2,INFO,Starting process_shard of 488 chunks.\n",
      "2023-04-23 23:03:49,940,credentials,ForkPoolWorker-2,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 23:03:49,972,load_data_into_opensearch,ForkPoolWorker-2,INFO,process_shard, there are 488 texts to be added\n",
      "2023-04-23 23:03:53,324,sm_helper,ForkPoolWorker-1,INFO,got results for 488 in 66.47709202766418s, length of embeddings list is 488\n",
      "2023-04-23 23:03:56,951,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:2.007s]\n",
      "2023-04-23 23:03:57,645,base,ForkPoolWorker-1,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.677s]\n",
      "2023-04-23 23:03:57,674,load_data_into_opensearch,ForkPoolWorker-1,INFO,Shard completed in 70.90136766433716 seconds.\n",
      "2023-04-23 23:04:49,384,sm_helper,ForkPoolWorker-2,INFO,got results for 488 in 59.411513805389404s, length of embeddings list is 488\n",
      "2023-04-23 23:04:53,367,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:2.241s]\n",
      "2023-04-23 23:04:54,128,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:0.750s]\n",
      "2023-04-23 23:04:54,154,load_data_into_opensearch,ForkPoolWorker-2,INFO,Shard completed in 64.24126482009888 seconds.\n",
      "2023-04-23 23:04:54,156,load_data_into_opensearch,ForkPoolWorker-2,INFO,Starting process_shard of 488 chunks.\n",
      "2023-04-23 23:04:54,176,credentials,ForkPoolWorker-2,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 23:04:54,205,load_data_into_opensearch,ForkPoolWorker-2,INFO,process_shard, there are 488 texts to be added\n",
      "2023-04-23 23:06:03,358,sm_helper,ForkPoolWorker-2,INFO,got results for 488 in 69.15207314491272s, length of embeddings list is 488\n",
      "2023-04-23 23:06:06,861,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_bulk [status:200 request:1.859s]\n",
      "2023-04-23 23:06:08,156,base,ForkPoolWorker-2,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/sagemakerdocs2/_refresh [status:200 request:1.283s]\n",
      "2023-04-23 23:06:08,176,load_data_into_opensearch,ForkPoolWorker-2,INFO,Shard completed in 74.01918935775757 seconds.\n",
      "2023-04-23 23:06:08,225,credentials,MainProcess,INFO,Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2023-04-23 23:06:08,599,base,MainProcess,INFO,POST https://search-embeddings-buoah4vj6ik2cs2uylbofql5au.us-east-1.es.amazonaws.com:443/_count [status:200 request:0.110s]\n",
      "2023-04-23 23:06:08,599,load_data_into_opensearch,MainProcess,INFO,run time in seconds: 559.90, index count={'count': 101005, '_shards': {'total': 172, 'successful': 172, 'skipped': 0, 'failed': 0}}\n",
      "2023-04-23 23:06:08,599,load_data_into_opensearch,MainProcess,INFO,all done\n"
     ]
    }
   ],
   "source": [
    "!python  container/load_data_into_opensearch.py --opensearch-cluster-domain $OS_DOMAIN_EP \\\n",
    "--opensearch-secretid $OS_CREDS_SECRETID_IN_SECRETS_MANAGER \\\n",
    "--opensearch-index-name $DOMAIN_`date +%s` \\\n",
    "--aws-region $region \\\n",
    "--embeddings-model-endpoint-name $embedding_model_endpoint_name \\\n",
    "--chunk-size-for-doc-split $CHUNK_SIZE_FOR_DOC_SPLIT \\\n",
    "--chunk-overlap-for-doc-split $CHUNK_OVERLAP_FOR_DOC_SPLIT \\\n",
    "--input-data-dir $DOMAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016a278-9e64-43bd-867f-1adb87136bd0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load the data in a `OpenSearch` index via SageMaker Processing Job (Distributed mode)\n",
    "\n",
    "We now have a working script that is able to ingest data into an OpenSearch index. But for this to work for massive amounts of data we need to scale up the processing by running this code in a distributed fashion. We will do this using Sagemkaer Processing Job. This involves the following steps:\n",
    "\n",
    "1. Create a custom container in which we will install the `langchain` and `opensearch-py` packges and then upload this container image to Amazon Elastic Container Registry (ECR).\n",
    "2. Use the Sagemaker `ScriptProcessor` class to create a Sagemaker Processing job that will run on multiple nodes.\n",
    "    - The data files available in S3 are automatically distributed across in the Sagemaker Processing Job instances by setting `s3_data_distribution_type='ShardedByS3Key'` as part of the `ProcessingInput` provided to the processing job.\n",
    "    - Each node processes a subset of the files and this brings down the overall time required to ingest the data into Opensearch.\n",
    "    - Each node also uses Python `multiprocessing` to internally also parallelize the file processing. Thus, **there are two levels of parallelization happening, one at the cluster level where individual nodes are distributing the work (files) amongst themselves and another at the node level where the files in a node are also split between multiple processes running on the node**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cced6-5e83-46d3-9c6e-cb0602f1ddf3",
   "metadata": {},
   "source": [
    "### Create custom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a91204c0-0cd2-45f1-b98e-56927fa04764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/Dockerfile\n",
    "\n",
    "FROM python:3.9-slim-buster\n",
    "\n",
    "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
    "         wget \\\n",
    "         python3-pip \\\n",
    "         python3-setuptools \\\n",
    "         nginx \\\n",
    "         ca-certificates \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN ln -s /usr/bin/python3 /usr/bin/python\n",
    "RUN ln -s /usr/bin/pip3 /usr/bin/pip\n",
    "\n",
    "# pip leaves the install caches populated which uses a \n",
    "# significant amount of space. These optimizations save a fair \n",
    "# amount of space in the image, which reduces start up time.\n",
    "RUN pip --no-cache-dir install  langchain==0.0.144 opensearch-py==2.2.0 sagemaker==2.148.0 beautifulsoup4==4.12.2\n",
    "\n",
    "# Include python script for retrieving credentials \n",
    "# from AWS SecretsManager and Sagemaker helper classes\n",
    "ADD credentials.py /code/\n",
    "ADD sm_helper.py /code/\n",
    "\n",
    "# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\n",
    "# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\n",
    "# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\n",
    "# PATH so that the train and serve programs are found when the container is invoked.\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f4f075b-e8c5-41d8-9073-a4ace9eec175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/build_and_push.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/build_and_push.sh\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
    "# by SageMaker.\n",
    "# The argument to this script are the path to the Dockerfile, the image name and tag and the aws-region\n",
    "# in which the container is to be created. This will be used as the image on the local\n",
    "# machine and combined with the account and region to form the repository name for ECR.\n",
    "\n",
    "# override the built-in echo so that we can have a nice timestamped trace\n",
    "echo () {\n",
    "    builtin echo \"$(date +'[%m-%d %H:%M:%S]'):\" \"$@\"\n",
    "}\n",
    "\n",
    "if [ \"$#\" -eq 4 ]; then\n",
    "    dlc_account_id=$(aws sts get-caller-identity | jq .Account)\n",
    "    path_to_dockerfile=$1\n",
    "    image=$2\n",
    "    tag=$3\n",
    "    region=$4\n",
    "    \n",
    "else\n",
    "    echo \"missing mandatory command line arguments, see usage...\"\n",
    "    echo \"usage: $0 </path/to/Dockerfile> $1 <image-repo> $2 <image-tag> $3 <aws-region>\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Get the account number associated with the current IAM credentials\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    exit 255\n",
    "fi\n",
    "\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image}:${tag}\"\n",
    "echo the full image name would be ${fullname}\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --region ${region} --repository-names \"${image}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"creating ECR repository : ${fullname} \"\n",
    "    aws ecr create-repository --region ${region} --repository-name \"${image}\" > /dev/null\n",
    "else\n",
    "    echo \"${image} repo already exists in ECR\"\n",
    "fi\n",
    "\n",
    "# move to path of dockerfile\n",
    "cd ${path_to_dockerfile}\n",
    "\n",
    "# get credentials to login to ECR and, build and tag the image\n",
    "# note the use of DOCKER_BUILDKIT=1, this is needed for some mount instructions in the Dockerfile\n",
    "echo \"going to start a docker build, image=${image}, using Dockerfile=${path_to_dockerfile}\"\n",
    "aws ecr get-login-password --region ${region} \\\n",
    "| docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\n",
    "DOCKER_BUILDKIT=1 docker build . -t ${image}  --build-arg dlc_account_id=${dlc_account_id} --build-arg region=${region}\n",
    "docker tag ${image} ${fullname}\n",
    "echo ${image} created\n",
    "\n",
    "# push the image to ECR\n",
    "cmd=\"aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\"\n",
    "echo going to run \\\"${cmd}\\\" to login to ECR\n",
    "${cmd}\n",
    "\n",
    "cmd=\"docker push ${fullname}\"\n",
    "echo going to run \\\"${cmd}\\\" to push image to ecr\n",
    "${cmd}\n",
    "if [ $? -eq 0 ]; then\n",
    "    echo \"Amazon ECR URI: ${fullname}\"\n",
    "else\n",
    "    echo \"Error: Image ${fullname} build and push failed\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"all done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0c76456-f381-44b2-ae35-70563e9cb4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 23:18:50,614,1969809775,MainProcess,INFO,region=us-east-1, account_id=015469603702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04-23 23:18:52]: the full image name would be 015469603702.dkr.ecr.us-east-1.amazonaws.com/load-data-opensearch-custom:latest\n",
      "[04-23 23:18:52]: load-data-opensearch-custom repo already exists in ECR\n",
      "[04-23 23:18:52]: going to start a docker build, image=load-data-opensearch-custom, using Dockerfile=/home/ec2-user/SageMaker/repos/qa-w-rag-finetuned-llm/container\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (3/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.26kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.9-slim-buster  0.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (12/12) FINISHED                                              \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.26kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.9-slim-buster  0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2.57kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [1/7] FROM docker.io/library/python:3.9-slim-buster@sha256:1c5091a9ba  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/7] RUN apt-get -y update && apt-get install -y --no-install  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/7] RUN ln -s /usr/bin/python3 /usr/bin/python                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/7] RUN ln -s /usr/bin/pip3 /usr/bin/pip                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/7] RUN pip --no-cache-dir install  langchain==0.0.144 opens  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [6/7] ADD credentials.py /code/                                 0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [7/7] ADD sm_helper.py /code/                                   0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:c29a02102d45604d6c3b01b9c00bdfab7b8467e941a9a  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/load-data-opensearch-custom             0.0s\n",
      "\u001b[0m\u001b[?25h[04-23 23:18:53]: load-data-opensearch-custom created\n",
      "[04-23 23:18:53]: going to run \"aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 015469603702.dkr.ecr.us-east-1.amazonaws.com\" to login to ECR\n",
      "\n",
      "Unknown options: |,docker,login,--username,AWS,--password-stdin,015469603702.dkr.ecr.us-east-1.amazonaws.com\n",
      "[04-23 23:18:54]: going to run \"docker push 015469603702.dkr.ecr.us-east-1.amazonaws.com/load-data-opensearch-custom:latest\" to push image to ecr\n",
      "The push refers to repository [015469603702.dkr.ecr.us-east-1.amazonaws.com/load-data-opensearch-custom]\n",
      "\n",
      "\u001b[1Bf75d6937: Preparing \n",
      "\u001b[1B3f3d320a: Preparing \n",
      "\u001b[1B8df3d21c: Preparing \n",
      "\u001b[1Be8f56678: Preparing \n",
      "\u001b[1B6c1802b8: Preparing \n",
      "\u001b[1Bdeddf97e: Preparing \n",
      "\u001b[1B14f8f869: Preparing \n",
      "\u001b[1B5e26aee2: Preparing \n",
      "\u001b[1Bc464aee1: Preparing \n",
      "\u001b[1B0df26c61: Preparing \n",
      "\u001b[1Bc84a1270: Layer already exists \u001b[6A\u001b[2K\u001b[1A\u001b[2Klatest: digest: sha256:588ee0d54b5264cf6221e71c729c70145eeb6888194d74b60a74f5055a9025be size: 2623\n",
      "[04-23 23:18:54]: Amazon ECR URI: 015469603702.dkr.ecr.us-east-1.amazonaws.com/load-data-opensearch-custom:latest\n",
      "[04-23 23:18:54]: all done\n"
     ]
    }
   ],
   "source": [
    "# Run script to build docker custom containe image and push it to ECR \n",
    "# Set region and sagemaker URI variables \n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "client = boto3.client(\"sts\")\n",
    "account_id = client.get_caller_identity()[\"Account\"]\n",
    "logger.info(f\"region={region}, account_id={account_id}\")\n",
    "!bash scripts/build_and_push.sh $(pwd)/container $IMAGE $IMAGE_TAG $region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0022cd-0934-45ef-8741-5a9ebd7cd6fe",
   "metadata": {},
   "source": [
    "### Create and run the Sagemaker Processing Job\n",
    "\n",
    "Now we will run the Sagemaker Processing Job to ingest the data into OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bb019-8b4c-4ff0-8f1f-0b7deaaf5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the parameters for the job\n",
    "base_job_name = \"ingest-data-to-opensearch\"\n",
    "tags = [{\"Key\": \"data\", \"Value\": \"embeddings-for-llm-apps\"}]\n",
    "\n",
    "# use the custom container we just created\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{IMAGE}:{IMAGE_TAG}\"\n",
    "\n",
    "# instance type and count determined via trial and error: how much overall processing time\n",
    "# and what compute cost works best for your use-case\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "instance_count = 3\n",
    "logger.info(f\"base_job_name={base_job_name}, tags={tags}, image_uri={image_uri}, instance_type={instance_type}, instance_count={instance_count}\")\n",
    "\n",
    "# setup the ScriptProcessor with the above parameters\n",
    "processor = ScriptProcessor(base_job_name=base_job_name,\n",
    "                            image_uri=image_uri,\n",
    "                            role=role,\n",
    "                            instance_type=instance_type,\n",
    "                            instance_count=instance_count,\n",
    "                            command=[\"python3\"],\n",
    "                            tags=tags)\n",
    "\n",
    "# setup input from S3, note the ShardedByS3Key, this ensures that \n",
    "# each instance gets a random and equal subset of the files in S3.\n",
    "inputs = [ProcessingInput(source=S3_DATA_SOURCE,\n",
    "                          destination='/opt/ml/processing/input_data',\n",
    "                          s3_data_distribution_type='ShardedByS3Key',\n",
    "                          s3_data_type='S3Prefix')]\n",
    "\n",
    "# create a new opensearch index name everytime to avoid name collision\n",
    "os_index_name = f\"sagemakerdocs_{int(time.time())}\"\n",
    "\n",
    "# read to run the processing job\n",
    "st = time.time()\n",
    "processor.run(code=\"container/load_data_into_opensearch.py\",\n",
    "              inputs=inputs,\n",
    "              outputs=[],\n",
    "              arguments=[\"--opensearch-cluster-domain\", OS_DOMAIN_EP,\n",
    "                         \"--opensearch-secretid\", OS_CREDS_SECRETID_IN_SECRETS_MANAGER,\n",
    "                         \"--opensearch-index-name\", os_index_name,\n",
    "                         \"--aws-region\", region,\n",
    "                         \"--embeddings-model-endpoint-name\", embedding_model_endpoint_name,\n",
    "                         \"--chunk-size-for-doc-split\", CHUNK_SIZE_FOR_DOC_SPLIT,\n",
    "                         \"--chunk-overlap-for-doc-split\", CHUNK_OVERLAP_FOR_DOC_SPLIT,\n",
    "                         \"--input-data-dir\", \"/opt/ml/processing/input_data\"])\n",
    "time_taken = time.time() - st\n",
    "logger.info(f\"processing job completed, total time taken={time_taken}s\")\n",
    "preprocessing_job_description = processor.jobs[-1].describe()\n",
    "logger.info(preprocessing_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a77e03-b631-4fb7-9c39-dbe7afcec737",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a43f6-ca23-484d-a3c1-c84292c83112",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f8f33-862c-44d2-9403-219f8c1d12b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
